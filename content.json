{"pages":[],"posts":[{"title":"TPU 한달 무제한 사용기 - TFRC (1)","text":"왜 TPU를 해야하는가?요즘 논문들을 읽다보면 많은 분야에서 모델의 크기가 계속해서 커지고 있습니다. Transformer 이후로 NLP 모델들은 계속 커져가고 GPT-3의 경우는 개인이 학습시키는 일은 불가능하며 이미지 모델들도 Transformer 영향을 받은 DeTR 외에도 점점 GPU 요구량이 커지고 있습니다. 그래서 저는 돈없는 학생으로서 살아남기위해 엄청난 메모리와 계산력을 가진 TPU를 공부하기로 마음먹었습니다. Multilingual Model 대회에 참가한 적이 있는데, XLM-Roberta Large 학습에서 GTX-1080Ti로는 3일 소요되지만 TPU-v2로는 1시간 걸리는 걸 보고 TPU가 추후에 많이 활용될 거 같다고 느꼈습니다. TPU 성능 그림 1. TPU 성능 비교표. Task에 따라 달라질 수 있지만 이 포스트에서는 자세히 다루지 않을 예정이다. TPU 사용 방법TPU 사용할 수 있는 방법은 현재 3가지가 있습니다. Colab Kaggle Notebook GCP를 통한 TPU API 활용 Colab과 Kaggle Notebook의 경우는 무료로 제공하기 때문에 메모리와 시간제약이 있습니다. Colab Pro의 경우도 TPU를 하루종일 사용하면 한동안 사용이 불가능합니다. Kaggle Notebook은 16GB 메모리 제한과 1회 3시간 이용가능한 제한이 있습니다. 그래서 가장 자유롭게 사용하는 방법은 GCP를 통해 TPU를 사용하는 방법입니다. 위 두 방법과는 다르게 유료이지만 연구자라면 한달동안 TFRC를 통해 5 * TPU-v2, 5 * TPU-v3, 조건적인 100 * TPU-v2. 최대 100개 이상의 TPU를 한달간 무제한으로 사용할 수 있습니다. TFRC 신청TFRC는 Tensorflow Research Cloud 웹페이지에서 신청할수 있습니다. ( https://www.tensorflow.org/tfrc?hl=ko ) TFRC 웹페이지에서 ‘지금 적용하기’ 클릭 Google Form에 간단한 정보 작성 (이름, 소속, 이메일, …) GCP 계정과 연결 위의 google form을 보내면, 적었던 메일로 확인 메일이 하나 온다. 여기서 GCP 계정정보를 적어서 전달합니다. TPU API 한달 무료이용 등록완료 위 메일이 날라오면 이제부터 31일간 TPU를 무료로 이용할 수 있습니다. 이 후 포스팅에서 GCP bucket과 VM을 통해 TPU 환경을 세팅 및 실제 이미지 데이터를 학습하는 과정을 적어보도록 하겠습니다.","link":"/2020/07/04/TPU-%ED%95%9C%EB%8B%AC-%EB%AC%B4%EC%A0%9C%ED%95%9C-%EC%82%AC%EC%9A%A9%EA%B8%B0-TFRC-1/"},{"title":"TPU 한달 무제한 사용기 - TFRC (2) Bucket, VM Instance","text":"GCP Console Project 생성 1편에서 두번째 Google Form에 GCP 프로젝트 정보를 전달하기위해 Project를 하나 생성하여야합니다. 프로젝트 이름을 입력하고 생성합니다. GCP Bucket과 VM Instance 생성처음 프로젝트를 생성하면 아무것도 없기때문에, 새로 Bucket과 VM Instance를 생성해야합니다. Bucket은 Cloud Storage로써 데이터를 저장하는 역할을 합니다. TPU 계산에서는 로컬디스크의 데이터를 사용할 수 없기때문에 반드시 Bucket을 만들어야합니다. VM Instance는 계산을 진행하는 환경입니다. 해당 환경에는 기본적인 CPU와 RAM이 갖춰져있고, GPU도 추가적으로 설정이 가능합니다. 위 두 가지를 세팅하기 위해 GCP 터미널을 열어줍니다. GCP Bucket 생성GCP 터미널에 아래 커멘드를 적어줍니다. 맨 위에 설정 정보가 있고 원하시는 이름으로 바꾸셔서 설정하셔도 가능합니다. 저는 5개 TPU v2-8를 us-central1-f 지역으로 할당받아서, 이 지역으로 설정하였습니다. 할당받은 TPU region은 2번째 tfrc 메일을 확인하시면 나와있습니다. 1234567891011121314# Project Name : tpu-boost# tpu region: us-central1-f# bucket name: us-tpu-bucket# tpu name: us-tpu1# 초기 설정export PROJECT_NAME=tpu-boostgcloud config set project $PROJECT_NAMEgcloud config set compute/zone us-central1-fgcloud config set compute/region us-central1-f# Bucket 생성gsutil mb -p ${PROJECT_NAME} -c standard -l us-central1 -b on gs://us-tpu-bucket TPU VM Instacne 생성12345# TPU Instance 생성ctpu up --tf-version=2.2 --tpu-size=v2-8 --name=us-tpu1 --zone=us-central1-f# TPU Instance에 접속gcloud compute ssh us-tpu1 --zone=us-central1-f TPU Instance에 접속하실 때, passphrase는 그냥 엔터로 넘어가셔도 됩니다. 그럼 이렇게 us-tpu1이라는 TPU Instance에 접속되는 걸 볼 수 있습니다. MNIST 예제 실행TPU Instance의 터미널에서 아래 코드를 적으면 TPU를 통한 MNIST 학습이 진행됩니다. 12345678910111213141516171819202122232425# Project Name : tpu-boost# tpu region: us-central1-f# bucket name: us-tpu-bucket# tpu name: us-tpu1# bucket에서 파일을 복사gsutil -m cp -r gs://us-tpu-bucket/* ~/# MNIST 실행 설정export STORAGE_BUCKET=gs://us-tpu-bucketexport TPU_NAME=us-tpu1export MODEL_DIR=$STORAGE_BUCKET/mnistexport DATA_DIR=gs://tfds-data/datasetsexport PYTHONPATH=\"$PYTHONPATH:/usr/share/models\"pip3 install tensorflow-model-optimizationcd /usr/share/models/official/vision/image_classificationpython3 mnist_main.py \\ --tpu=$TPU_NAME \\ --model_dir=$MODEL_DIR \\ --data_dir=$DATA_DIR \\ --train_epochs=10 \\ --distribution_strategy=tpu \\ --download 상당히 빠른 속도로 학습이 진행되는걸 볼 수 있습니다. 다음 포스팅에선 ssh, jupyter notebook 환경 세팅을 알아보겠습니다. Reference Quickstart Guide: https://cloud.google.com/tpu/docs/quickstart","link":"/2020/07/05/TPU-%ED%95%9C%EB%8B%AC-%EB%AC%B4%EC%A0%9C%ED%95%9C-%EC%82%AC%EC%9A%A9%EA%B8%B0-TFRC-2-Bucket-VM-Instance/"},{"title":"TPU 한달 무제한 사용기 - TFRC (3) ssh, jupyter notebook","text":"TPU Instance 환경 설정IT 분야에서 코딩을 하시는 분이라면 원격으로 일하는 건 필수일 것입니다. 특히나 개인 장비로는 일을 할 수 없는 머신러닝은 더더욱 필수적입니다. 그래서 이번 포스팅에서는 GCP VM Instance에서 ssh 접속과 jupyter notebook을 활성화하는 방법을 알아보겠습니다. SSH 설정외부 접속이 가능할 수 있도록 ssh 설정을 바꿔야합니다. VM Instance 내부 터미널에서 아래 커맨드를 실행시킵니다. 1sudo vi /etc/ssh/sshd_config 12345678### 위 그림과 같이 아래 설정을 추가, 변경해줍니다.# 추가AllowTcpForwarding yesGatewayPorts yesTCPKeepAlive yes# 변경PasswordAuthentication yes 그리고 ssh를 재실행시켜줍니다. 1sudo service ssh restart User 추가sudo 권한을 가진 계정을 하나 추가해줍니다. 이 계정은 ssh를 이용해서 계속 사용할 것입니다. 12345# UserID: hslee1sudo useradd hslee1sudo passwd hslee1sudo usermod -a -G sudo hslee1 저는 hslee1이라는 계정을 만들었습니다. 외부 IP 확인GCP 페이지에서 Computer Engine &gt; VM 인스턴스 에서 인스턴스의 외부 IP를 확인할 수 있습니다. 아래 빨간 박스의 아이피를 복사한 후, 외부 터미널에 접속합니다. 12# UserID: hslee1ssh hslee1@xxx.xxx.xx.xxx 위 커맨드를 실행하면 gcp instance에 접속이 된걸 확인할 수 있습니다. Jupyter Notebook 설정Jupyter Notebook을 설정하기 위해 다시 VM Instance 터미널로 돌아옵니다. 1234567891011# Jupyter Lab 설치pip3 install jupyterlab # Jupyter Lab 실행이 가능하도록 설정jupyter serverextension enable --py jupyterlab --user# 현재 interpreter를 jupyter에서 'tpu'라는 커널으로 사용할 수 있도록 설정python3 -m ipykernel install --user --name tpu --display-name \"tpu\"# Jupyter Notebook 실행jupyter notebook --ip=0.0.0.0 --NotebookApp.token='' 위 커맨드를 실행하고 외부 아이피:8888/lab (xxx.xxx.xx.xxx:8888/lab)으로 접속하면, 성공적으로 접속이 됩니다.","link":"/2020/07/05/TPU-%ED%95%9C%EB%8B%AC-%EB%AC%B4%EC%A0%9C%ED%95%9C-%EC%82%AC%EC%9A%A9%EA%B8%B0-TFRC-3-ssh-jupyter-notebook/"},{"title":"GCP Bucket 파일 전송하기","text":"GCP Bucket을 이용하기 위해선 데이터를 전송하고 받아야한다. Local Machine → GCP Bucket12345# OBJECT_LOCATION: Local 위치# DESTINATION_BUCKET_NAME: Bucket 위치# 이 커맨드는 Local Machine에서 실행한다.gsutil cp [OBJECT_LOCATION] gs://[DESTINATION_BUCKET_NAME]/ Bucket → VM Instance12345# DESTINATION_BUCKET_NAME: Bucket 위치# VM_LOCATION: VM Instance에 복사받을 위치# 이 커맨드는 VM Instance 터미널에서 실행을 한다.gsutil cp gs://[DESTINATION_BUCKET_NAME]/ [VM_LOCATION] 병렬로 전송하기12345# gcp-bucket-name: GCP bucket 이름# 아래 커맨드는 병렬로 gcp-bucket-name의 전체 파일을 현재 머신에 옮긴다.# -m을 통해 기본 copy보다 빠르게 복사한다.gsutil -m cp -r gs://gcp-bucket-name/* ~/ Reference Google Doc: https://cloud.google.com/storage/docs/gsutil/commands/cp","link":"/2020/07/05/GCP-Bucket-%ED%8C%8C%EC%9D%BC-%EC%A0%84%EC%86%A1%ED%95%98%EA%B8%B0/"},{"title":"Cityscapes Dataset script로 다운받기","text":"1234567# Log-inexport USERID=myusernameexport PASSWORD=mypasswordwget --keep-session-cookies --save-cookies=cookies.txt --post-data 'username=$USERID&amp;password=$PASSWORD&amp;submit=Login' https://www.cityscapes-dataset.com/login/# Downloadwget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=1 PackageID에 따른 파일명1 → gtFine_trainvaltest.zip (241MB)2 → gtCoarse.zip (1.3GB)3 → leftImg8bit_trainvaltest.zip (11GB)4 → leftImg8bit_trainextra.zip (44GB)8 → camera_trainvaltest.zip (2MB)9 → camera_trainextra.zip (8MB)10 → vehicle_trainvaltest.zip (2MB)11 → vehicle_trainextra.zip (7MB)12 → leftImg8bit_demoVideo.zip (6.6GB)28 → gtBbox_cityPersons_trainval.zip (2.2MB) Reference Download City Scapes Dataset with script: https://towardsdatascience.com/download-city-scapes-dataset-with-script-3061f87b20d7","link":"/2020/07/16/Cityscapes-Dataset-script%EB%A1%9C-%EB%8B%A4%EC%9A%B4%EB%B0%9B%EA%B8%B0/"},{"title":"NodeJS, npm 설치","text":"Windows NodeJS Download → https://nodejs.org/en/download/ 설치 완료 후 Version 확인 Linux Shell Script를 통한 설치 123456# =================================# NodeJS# =================================apt-get updatecurl -sL https://deb.nodesource.com/setup_12.x | bash - &amp;&amp; \\apt-get install -y nodejs 설치 완료 후 Version 확인","link":"/2020/07/16/NodeJS-npm-%EC%84%A4%EC%B9%98/"},{"title":"GCP VM Instance 만들기","text":"GCP 가입 후, VM 인스턴스 만드는 방법은 간단합니다. GCP 홈페이지에서 콘솔로 이동하신 후, 프로젝트를 하나 만듭니다. 프로젝트 만들기 왼쪽 상단에 프로젝트 목록 선택 새 프로젝트 클릭 새 프로젝트 설정. 결제 계정은 GCP를 처음 이용한다면 $300 credit을 제공합니다. VM 인스턴스 만들기 인스턴스 만들기 클릭 이름, 지역, 머신 설정. 서울은 지원안하는 서비스가 있어서 도쿄로 하였습니다. 또한 저는 딥러닝 모델 서빙목적이기때문에, n1-standard2를 선택하였습니다. 운영체제는 Ubuntu 18.04로 진행합니다. 외부접속 허용을 위해 HTTP 트래픽을 허용해주고, 만들기를 합니다. 그럼 위와 같이 VM 인스턴스를 만들수있습니다 !","link":"/2020/07/17/GCP-VM-Instance-%EB%A7%8C%EB%93%A4%EA%B8%B0/"},{"title":"Ubuntu에서 Chrome Remote Desktop 설정","text":"VNCserver 설치데스크탑 환경설치123sudo apt install ubuntu-gnome-desktopsudo systemctl enable gdmsudo systemctl start gdm VNC 설치123sudo apt-get updatesudo apt install tigervnc-standalone-server tigervnc-xorg-extension tigervnc-viewervncserver VNC 설정1vim ~/.vnc/xstartup 123456#!/bin/sh# Start Gnome 3 Desktop [ -x /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup[ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresourcesvncconfig -iconic &amp;dbus-launch --exit-with-session gnome-session &amp; 1vncserver -kill :1 VNC 실행 및 제거12vncserver -localhost no -geometry 1920x1080 :4099# vncserver -kill :4099 VNC 화면 Chrome Remote Desktop 설치Chrome 설치1234567wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add - sudo sh -c 'echo \"deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main\" &gt;&gt; /etc/apt/sources.list.d/google.list'sudo apt-get updatesudo apt-get install google-chrome-stable Chrome Remote Desktop App 설치 chrome remote desktop 홈페이지에서 deb파일을 다운받습니다. 설치 1234sudo dpkg -i chrome-remote-desktop_current_amd64.debsudo apt-get -f installsudo dpkg -i chrome-remote-desktop_current_amd64.debsudo chkconfig --list |grep chrome 가상 데스크톱 세션 맞춤설정 /usr/share/xsessions/에서 gnome.desktop열기 Exec= 뒤의 명령어 복사 (Exec=/usr/bin/gnome-session –session=gnome) vi ~/.chrome-remote-desktop-session 1exec /etc/X11/Xsession '/usr/bin/gnome-session --session=gnome' 원격 데스크톱 다시 시작 후 접속 성공!!! Reference VNC 설치: https://0902.tistory.com/24 크롬 설치: https://snowdeer.github.io/linux/2018/02/02/ubuntu-16p04-install-chrome/ 리모트 데스크톱 설치: https://linuxcommando.blogspot.com/2014/08/chrome-remote-desktop-connects-from.html 가상 데스크톱 세션설정: https://support.google.com/chromebook/answer/1649523?co=GENIE.Platform%3DDesktop&amp;hl=ko","link":"/2020/07/20/Ubuntu%EC%97%90%EC%84%9C-Chrome-Remote-Desktop-%EC%84%A4%EC%A0%95/"},{"title":"Docker Remote Interpreter Setting In PyCharm","text":"Docker Remote Interpreter SettingWorking at home, we want to connect the server’s interpreter. This is how to do that. Open Docker TCP Socket (Server) Make a docker-tcp configuration file 1vi /etc/systemd/system/docker-tcp.socket Write this content and Save 12345678910[Unit]Description=Docker Socket for the API[Socket]ListenStream=2375BindIPv6Only=bothService=docker.service[Install]WantedBy=sockets.target Restart docker &amp; Enable TCP connection 1234sudo systemctl enable docker-tcp.socketsudo systemctl stop dockersudo systemctl start docker-tcp.socketsudo systemctl start docker Tunneling (Home)12345# ssh -L ${HomePort}:${ServerAddress}:${ServerPort}ssh -L 2375:server-address:2375# Advanced (Tunneling through another server)ssh -L ${HomePort}:${ServerAddress}:${ServerPort} -Nfl ${UserName} ${AnotherServer} -p ${port} PyCharm Docker Setting Settings &gt; Build &gt; Docker : Write server &amp; port (2375) PyCharm Interpreter Setting Settings &gt; Project &gt; Interpreter &gt; Add from docker","link":"/2020/07/28/Docker-Remote-Interpreter-Setting-In-PyCharm/"},{"title":"[에러 해결] Failed to initialize NVML: Driver&#x2F;library version mismatch","text":"문제1Failed to initialize NVML: Driver/library version mismatch 해결방법 nvidia 관련 사용중인 드라이브 확인 1lsmod | grep nvidia nvidia_uvm 966656 0nvidia_drm 45056 6nvidia_modeset 1114112 5 nvidia_drmnvidia 20680704 328 nvidia_uvm,nvidia_modeset nvidia unload 하기 1234sudo rmmod nvidia_uvm sudo rmmod nvidia_drmsudo rmmod nvidia_modeset sudo rmmod nvidia 기타 에러 해결법rmmod: ERROR: Module nvidia_drm is in use systemctl isolate multi-user.target sudo modprobe -r nvidia-drm systemctl start graphical.target rmmod: ERROR: Module nvidia is in use nvidia 사용중인 프로세스 확인sudo lsof /dev/nvidia* 해당 process 종료하기sudo kill -9 PID nvidia-smi 로 확인해보면 정상적으로 작동","link":"/2021/01/13/%EC%97%90%EB%9F%AC-%ED%95%B4%EA%B2%B0-Failed-to-initialize-NVML-Driver-library-version-mismatch/"},{"title":"[Solution Summary] Prostate cANcer graDe Assessment (PANDA) Challenge","text":"대회 소개 (참조)전립선암이란?: 남성에게 가장 흔한 암 종류 중 하나입니다. 보통 전립선암은 천천히 자라고 전립선 안에만 있어 큰 위험요소는 아니지만 특정 종류의 전립선 암은 매우 빠르게 자라고 퍼집니다. 전립선 암 검사 Digital rectal exam (DRE): 의사가 장갑을 끼고 직장에 손을 넣어 전립선의 질감, 모양, 크기를 통해 이상을 탐지합니다. Prostate-specific antigen (PSA) test: 정맥의 혈액검사를 통해 PSA라는 전립선에서 분비되는 물질 검사를 합니다. 보통 적은 양이 분비되지만 이보다 많다면 전립선 감염, 염증 혹은 암이 의심됩니다. Ultrasound: 직장에 작은 크기의 도구를 넣어 음파를 통해 전립선 사진을 촬영합니다. Collecting a sample of prostate tissue: 모든 검사에서 암이 의심된다면 생체(조직) 검사를 통해 암을 판별합니다. 작은 침을 전립선에 넣어 조직을 수집하고 분석합니다. GLEASON score생체 검사를 통해 암이라고 확정받으면 암의 aggrerssive level을 판단합니다. 병리학자는 암 세포가 정상 세포에 비해 얼마나 다른지를 보고 판단하고 점수가 높을 수록 심각한 암입니다.Gleason score는 일반적으로 사용되는 전립선 암 점수입니다. 두 점수를 합산하여 범위는 2부터 10입니다. 2보다 낮은 점수는 보통 사용되지않습니다. ISUP gradeGLEASON score를 합산하여 ISUP grade를 나타냅니다. 범위는 1~5입니다. Gleason score 6 = ISUP grade 1 Gleason score 7 (3 + 4) = ISUP grade 2 Gleason score 7 (4 + 3) = ISUP grade 3 Gleason score 8 = ISUP grade 4 Gleason score 9-10 = ISUP grade 5 Gleason score 채점방식전립선 조직은 haematoxylin &amp; eosin(H&amp;E) 염색을 통해 염색됩니다. 조직은 내외분비샘 조직(glandular tissue)과 결합 조직(connective tissue)으로 구성됩니다.분비샘 조직은 하얗거나 가지친 구멍처럼 보이는 구조로 되어있습니다. 분비샘의 모습은 GLEASON score 채점의 기반이 됩니다. 건강한 분비샘 구조는 암이 심각해질 수록 모양을 잃게 되며 점수는 3, 4, 5로 증가합니다. 한글 의료 용어는 정확하지 않을 수 있습니다. 수정 사항이 있다면 알려주세요. [A]Benign prostate glands with folded epithelium(상피 접힌 전립선): 세포질은 창백하고 핵은 작고 규칙적입니다. 분비샘들은 함께 뭉쳐있습니다. [B]Prostatic adenocarcinoma(정위선암종): Gleason Pattern 3은 분비샘 모습의 손실이 없습니다. 작은 분비샘이 양성 분비샘 사이에 침투합니다. 세포질은 종종 어둡고 핵은 어두운 색소와 몇몇 두드러진 뉴클레오로 확대됩니다. 각 상피부에는 별도의 lumen이 있습니다. [C]Prostatic adenocarcinoma(정성 선종암): Gleason Pattern 4는 분비샘 모습 손실을 가지고 있습니다. Luminar를 형성하려는 시도가 있었지만 종양이 완전하고 잘 발달된 분비샘을 형성하는데 실패했습니다. 이 현미경 영상은 불규칙적인 암, 즉 다발성 luminar를 가진 상피부를 보여줍니다. 또한 잘 형성되지 않은 작은 분비샘과 퓨전된 분비샘도 있습니다. 이 모든 것이 Gleason Pattern 4에 포함되어 있습니다. [D]Prostatic adenocarcinoma(전립선 선암종): Gleason Pattern 5는 거의 완전한 분비샘 모습 손실을 가지고 있습니다. 분산되어 있는 단일 암세포가 stroma에서 발견됩니다. Gleason Pattern 5는 또한 암세포의 고체 시트나 가닥을 포함할 수 있습니다. 모든 현미경 사진에는 20배 렌즈 확대 시 hematoxylin &amp; eosin stains이 표시됩니다. 데이터 11,000 전립선 생체(조직)검사 whole-slide images (WSI) 각 WSI의 ISUP grade, GLEASON score 제공: Radboud University Medical Center, Karolinska Institutec Sample Images 이미지 크기는 x축과 y축 모두 5,000~40,000 px 사이로 큽니다. 이미지는 레벨 3까지 존재합니다 (1배, 4배, 16배 축소) 조직은 서로 다르게 회전되어있고 이에 큰 의미는 없습니다. 병리조직들의 색 차이는 매우 크고 이는 연구 절차 차이때문입니다. Label maskspixel-label mask 정보가 주어져있고 각 기관마다 다르게 표시하였습니다. Radboudumc: Prostate glands are individually labelled. Valid values are: 0: background (non tissue) or unknown 1: stroma (connective tissue, non-epithelium tissue) 2: healthy (benign) epithelium” 3: cancerous epithelium (Gleason 3) 4: cancerous epithelium (Gleason 4) 5: cancerous epithelium (Gleason 5) Karolinska: Regions are labelled. Valid values: 0: background (non tissue) or unknown 1: benign tissue (stroma and epithelium combined) 2: cancerous tissue (stroma and epithelium combined) 반자동적으로 생성되었기때문에 noisy합니다. 상위 Solutions 1st Place Solution Data Preprocessing Geting cleaned labels efficientnet-b1을 k-fold로 학습시킨 후, validation set에 대해 예측값을 낸다. ground truth와 isup grade의 차이가 클 경우 해당 데이터를 삭제한다. 12345678def remove_noisy(df, thresh): gap = np.abs(df[\"isup_grade\"] - df[\"probs_raw\"]) df_removed = df[gap &gt; thresh].reset_index(drop=True) df_keep = df[gap &lt;= thresh].reset_index(drop=True) return df_keep, df_removeddf_keep, df_remove = remove_noisy(df, thresh=1.6)show_keep_remove(df, df_keep, df_remove) Split: stratifed k-fold with imghash or stratified k-fold with gleason-score and imghash similarity Tile Method: iafoss tile method (tile size 192, tile num 64) Model Resnext50_32x4d: head(3 * reg_head + 1 * softmax head) Effnet-b1 + generalized-mean pooling Training Local train &amp; pred Remove noisy label Re-train Not worked Remove noisy by confident-learning Cycle GAN augmentation(karolinska radboud) test with AdaBN &amp; Freezing BN at train CutMix, Mixup (before denoising) 2nd Place Solution (1/2) Image Preprocessing Remove white background &amp; save medium resolution Remove pen marks &gt; Reduce Gap (CV, LB) Image Augmentation Full Slide: Shift, Scale, Rotation, Flip Patch: Rotation, VFlip Model ResNet34 Making Square Feature (iaofoss) Square Feature 이후, Squeeze &amp; Excitation Block 추가 Pooling (Remove BatchNormalization) Two Head (one for regression, one for classification) for regression, modified sigmoid is used to represent range(-1, 6) 123#idea taken from fastaidef sigmoid_range(x, low, high): return torch.sigmoid(x) * (high - low) + low Training Stage 1: 49 tiles Stage 2: 81 tiles One cycle Scheduler 2nd Place Solution (2/2) Huge Image Size iaofoss tile method Label Noise MSE loss on karolinska data Huber loss with delta 1 on radboud data (radbound is noiser) - lb0.9인데 radbound가 0.85인걸 보고 알아챔 3rd Place Solution 운 different networks and my custom tile cropping, hard augmentations iaofoss concat tile pooling method 기존의 방식은 whole slide를 resize를 한 후 예측하는 방식이지만, 이는 wholse slide의 비율에 따라 resize를 하였을 때, 이미지의 ratio도 달라지고 GPU도 빈공간이 많기때문에 효율적이지않음. 그래서 patch를 concatenate하여 encoder에 돌린 이후에 마지막 head에서 permute를 통해 prediction을 내는 방식. 123456789101112131415161718192021222324class Model(nn.Module): def __init__(self, arch='resnext50_32x4d_ssl', n=6, pre=True): super().__init__() m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', arch) self.enc = nn.Sequential(*list(m.children())[:-2]) nc = list(m.children())[-1].in_features self.head = nn.Sequential(AdaptiveConcatPool2d(),Flatten(),nn.Linear(2*nc,512), Mish(),nn.BatchNorm1d(512), nn.Dropout(0.5),nn.Linear(512,n)) def forward(self, *x): shape = x[0].shape n = len(x) x = torch.stack(x,1).view(-1,shape[1],shape[2],shape[3]) #x: bs*N x 3 x 128 x 128 x = self.enc(x) #x: bs*N x C x 4 x 4 shape = x.shape #concatenate the output for tiles into a single map x = x.view(-1,n,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous()\\ .view(-1,shape[1],shape[2]*n,shape[3]) #x: bs x C x N*4 x 4 x = self.head(x) #x: bs x n return x Reference PANDA - EDA + Better Visualization+Simple Baseline 1st Place Solution [PND] 2nd Place Solution [Save the Prostate] Part of 2nd place solution (only kaggle/colab TPU were used) 3rd place solution PANDA concat tile pooling starter [0.79 LB]","link":"/2021/02/07/Solution-Summary-Prostate-cANcer-graDe-Assessment-PANDA-Challenge/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","link":"/tags/Tutorial/"},{"name":"Summary","slug":"Summary","link":"/tags/Summary/"}],"categories":[{"name":"TPU","slug":"TPU","link":"/categories/TPU/"},{"name":"GCP","slug":"GCP","link":"/categories/GCP/"},{"name":"Set-Up","slug":"Set-Up","link":"/categories/Set-Up/"},{"name":"Competition","slug":"Competition","link":"/categories/Competition/"}]}